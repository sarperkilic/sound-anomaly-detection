{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dac4226f",
   "metadata": {},
   "source": [
    "In this notebook, the autoencoder architecture is used to develop an anomaly detection algorithm. \n",
    "   \n",
    "The training data are generated by computing a spectrogram from each signal and extracting features from these.\n",
    "\n",
    "    Network Architecture is described below:\n",
    "\n",
    "    Input shape: 640\n",
    "    Architecture:\n",
    "        Dense layer #1\n",
    "            Dense layer (units: 64)\n",
    "            Activation (ReLU)\n",
    "        Dense layer #2\n",
    "            Dense layer (units: 64)\n",
    "            Activation (ReLU)\n",
    "        Bottleneck layer\n",
    "            Dense layer (units: 8)\n",
    "            Batch Normalization\n",
    "            Activation (ReLU)\n",
    "        Dense layer #5\n",
    "            Dense layer (units: 64)\n",
    "            Activation (ReLU)\n",
    "        Dense layer #6\n",
    "            Dense layer (units: 64)\n",
    "            Activation (ReLU)\n",
    "        Output layer\n",
    "            Dense layer (units: 640)\n",
    "            \n",
    "    Learning (epochs: 200, batch size: 256, data shuffling between epochs)\n",
    "        Optimizer: Adam (learning rate: 0.001)\n",
    "        \n",
    "        \n",
    "        \n",
    "Model results shared below:\n",
    "\n",
    "Accuracy: 95.83%, Precision: 91.67%, Recall: 100.00%, F1: 95.65%\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9b68ff08",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/inovako/.local/lib/python3.6/site-packages/numba/core/errors.py:154: UserWarning: Insufficiently recent colorama version found. Numba requires colorama >= 0.3.9\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "import os\n",
    "import warnings\n",
    "import numpy as np\n",
    "from bokeh.io import export_svgs, output_notebook\n",
    "from bokeh.models import BoxAnnotation, ColumnDataSource, HoverTool\n",
    "from bokeh.plotting import figure, show\n",
    "\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    confusion_matrix,\n",
    "    f1_score,\n",
    "    precision_score,\n",
    "    recall_score,\n",
    "    average_precision_score,\n",
    "    precision_recall_curve,\n",
    "    roc_auc_score,\n",
    "    roc_curve,\n",
    ")\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "from utils import sound_tools\n",
    "from utils.misc import build_files_list, dump_pickle, load_pickle\n",
    "from utils.sound_utils import extract_signal_features, generate_dataset, load_sound_file\n",
    "from utils.measuring_performance import (\n",
    "    get_prediction,\n",
    "    plot_confusion_matrix,\n",
    "    plot_histogram_by_class,\n",
    "    plot_loss_per_epoch,\n",
    "    plot_pr_curve,\n",
    "    plot_roc_curve,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "53ec2642",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import Input\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.python.client import device_lib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "268d8ea0",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = \"./dataset\"\n",
    "IMAGE_PATH = \"./img\"\n",
    "MODEL_PATH = \"./models\"\n",
    "\n",
    "os.makedirs(os.path.join(DATA_PATH, \"dataset\"), exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05e7a826",
   "metadata": {},
   "source": [
    "# Data Splitting and Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0de7843",
   "metadata": {},
   "source": [
    "Only normal sound signals are used for training set. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "de462aec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set has 48 signals including abnormal 0 signals, but test set has 24 signals including abnormal 11 signals.\n"
     ]
    }
   ],
   "source": [
    "normal_files, abnormal_files = build_files_list(root_dir=DATA_PATH)\n",
    "normal_labels = np.zeros(len(normal_files))\n",
    "abnormal_labels = np.ones(len(abnormal_files))\n",
    "\n",
    "train_files, test_files, train_labels, test_labels = train_test_split(\n",
    "    normal_files, normal_labels, train_size=0.8, random_state=42, shuffle=True\n",
    ")\n",
    "\n",
    "test_files = np.concatenate((test_files, abnormal_files), axis=0)\n",
    "test_labels = np.concatenate((test_labels, abnormal_labels), axis=0)\n",
    "\n",
    "test_indices = np.arange(len(test_files))\n",
    "np.random.shuffle(test_indices)\n",
    "\n",
    "test_files = test_files[test_indices]\n",
    "test_labels = test_labels[test_indices]\n",
    "\n",
    "print(\n",
    "    f\"Train set has {train_labels.shape[0]} signals including abnormal {train_labels.sum():.0f} signals, \\\n",
    "but test set has {test_labels.shape[0]} signals including abnormal {test_labels.sum():.0f} signals.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "58f4a705",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = {\n",
    "    \"train_files\": train_files,\n",
    "    \"test_files\": test_files,\n",
    "    \"train_labels\": train_labels,\n",
    "    \"test_labels\": test_labels,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a093efc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "for key, values in dataset.items():\n",
    "    file_name = os.path.join(DATA_PATH, \"dataset\", key +  \".txt\")\n",
    "    with open(file_name, \"w\") as f:\n",
    "        for item in values:\n",
    "            f.write(str(item) + \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d521e81",
   "metadata": {},
   "source": [
    "Acoustic feature parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "92c62aa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_fft = 2048\n",
    "hop_length = 512\n",
    "n_mels = 64\n",
    "frames = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4e3b0844",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data already exists, loading from file...\n",
      "Train data has a (269616, 640) shape.\n"
     ]
    }
   ],
   "source": [
    "train_data_path = os.path.join(DATA_PATH, \"dataset\", \"train_data\" + \".pkl\")\n",
    "\n",
    "if os.path.exists(train_data_path):\n",
    "    print(\"Train data already exists, loading from file...\")\n",
    "    train_data = load_pickle(train_data_path)\n",
    "\n",
    "else:\n",
    "    train_data = generate_dataset(\n",
    "        train_files, n_fft=n_fft, hop_length=hop_length, n_mels=n_mels, frames=frames\n",
    "    )\n",
    "    print(\"Saving train data to disk...\")\n",
    "    dump_pickle(train_data_path, train_data)\n",
    "    print(\"Done.\")\n",
    "\n",
    "print(f\"Train data has a {train_data.shape} shape.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d1fb512",
   "metadata": {},
   "source": [
    "# Model Training and Prediction with AutoEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8621595a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def autoencoder(input_dims, model_name=None):\n",
    "    input_layer = Input(shape=(input_dims,))\n",
    "    output = Dense(64, activation=\"relu\")(input_layer)\n",
    "    output = Dense(64, activation=\"relu\")(output)\n",
    "    output = Dense(8, activation=\"relu\")(output)\n",
    "    output = Dense(64, activation=\"relu\")(output)\n",
    "    output = Dense(64, activation=\"relu\")(output)\n",
    "    output = Dense(input_dims, activation=None)(output)\n",
    "\n",
    "    return Model(inputs=input_layer, outputs=output, name=model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3e3f9bad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"AutoEncoder\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 640)]             0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 64)                41024     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 8)                 520       \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 64)                576       \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 640)               41600     \n",
      "=================================================================\n",
      "Total params: 92,040\n",
      "Trainable params: 92,040\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "MODEL_NAME = \"AutoEncoder\"\n",
    "MODEL_PATH = \"/home/inovako/Documents/audio/models/AutoEncoder.h5\"\n",
    "model = autoencoder(n_mels * frames, model_name=MODEL_NAME)\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "99cc80a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4min 15s, sys: 20.1 s, total: 4min 35s\n",
      "Wall time: 1min 11s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "batch_size = 256\n",
    "epochs = 200\n",
    "\n",
    "model.compile(\n",
    "    optimizer=Adam(learning_rate=1e-03),\n",
    "    loss=\"mean_squared_error\"\n",
    ")\n",
    "\n",
    "history = model.fit(\n",
    "    train_data,\n",
    "    train_data,\n",
    "    batch_size=batch_size,\n",
    "    epochs=epochs,\n",
    "    verbose=False,\n",
    "    callbacks=[EarlyStopping(monitor=\"val_loss\", patience=10)],\n",
    "    validation_split=0.1,\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "model.save(MODEL_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3581c412",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plot_loss_per_epoch(\n",
    "    history, model_name=MODEL_NAME, file_name=os.path.join(IMAGE_PATH, \"model_loss.svg\")\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40c48d40",
   "metadata": {},
   "source": [
    "![Loss plot](./img/model_loss.svg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c425d52c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9e9a911574784600971820d80e1d57d9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/24 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "recon_errors = []\n",
    "\n",
    "for index in tqdm(range(len(test_files))):\n",
    "    signal, sr = load_sound_file(test_files[index])\n",
    "\n",
    "    features = extract_signal_features(\n",
    "        signal, sr, n_fft=n_fft, hop_length=hop_length, n_mels=n_mels, frames=frames\n",
    "    )\n",
    "\n",
    "    predictions = model.predict(features)\n",
    "    mse = np.mean(np.mean(np.square(features - predictions), axis=1))\n",
    "    recon_errors.append(mse)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c29972fa",
   "metadata": {},
   "source": [
    "# Model Evaluation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "12c63bf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "stack = np.column_stack((range(len(recon_errors)), recon_errors))\n",
    "score_false = stack[test_labels == 0][:, 1]\n",
    "score_true = stack[test_labels == 1][:, 1]\n",
    "\n",
    "plot_histogram_by_class(\n",
    "    score_false,\n",
    "    score_true,\n",
    "    bins=[20, 30],\n",
    "    model_name=MODEL_NAME,\n",
    "    file_name=os.path.join(IMAGE_PATH, \"recon_error_dist.svg\"),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3706265",
   "metadata": {},
   "source": [
    "![Reconstruction Error](./img/recon_error_dist.svg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7fc78a4e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "THRESHOLD_MIN = 6.0\n",
    "THRESHOLD_MAX = 10.0\n",
    "THRESHOLD_STEP = 0.5\n",
    "\n",
    "p = figure(\n",
    "    plot_width=600,\n",
    "    plot_height=400,\n",
    "    title=f\"{MODEL_NAME}: Threshold Range Exploration\",\n",
    "    x_axis_label=\"Samples\",\n",
    "    y_axis_label=\"Reconstruction Error\",\n",
    ")\n",
    "\n",
    "source = ColumnDataSource(\n",
    "    dict(index=stack[test_labels == 0][:, 0], error=stack[test_labels == 0][:, 1])\n",
    ")\n",
    "p.scatter(\n",
    "    \"index\",\n",
    "    \"error\",\n",
    "    fill_alpha=0.6,\n",
    "    fill_color=\"crimson\",\n",
    "    line_color=None,\n",
    "    legend_label=\"Normal Signals\",\n",
    "    source=source,\n",
    ")\n",
    "\n",
    "source = ColumnDataSource(\n",
    "    dict(index=stack[test_labels == 1][:, 0], error=stack[test_labels == 1][:, 1])\n",
    ")\n",
    "p.scatter(\n",
    "    \"index\",\n",
    "    \"error\",\n",
    "    fill_alpha=0.6,\n",
    "    fill_color=\"indigo\",\n",
    "    line_color=None,\n",
    "    legend_label=\"Abnormal Signals\",\n",
    "    source=source,\n",
    ")\n",
    "\n",
    "source = ColumnDataSource(\n",
    "    data=dict(\n",
    "        index=stack[:, 0],\n",
    "        threshold_min=np.repeat(THRESHOLD_MIN, stack.shape[0]),\n",
    "        threshold_max=np.repeat(THRESHOLD_MAX, stack.shape[0]),\n",
    "    )\n",
    ")\n",
    "\n",
    "box = BoxAnnotation(\n",
    "    bottom=THRESHOLD_MIN,\n",
    "    top=THRESHOLD_MAX,\n",
    "    fill_alpha=0.1,\n",
    "    fill_color=\"magenta\",\n",
    "    line_color=\"darkmagenta\",\n",
    "    line_width=1.0,\n",
    ")\n",
    "p.add_layout(box)\n",
    "\n",
    "p.legend.label_text_font_size = \"8pt\"\n",
    "p.legend.location = \"top_right\"\n",
    "p.title.align = \"center\"\n",
    "p.title.text_font_size = \"12pt\"\n",
    "\n",
    "p.add_tools(HoverTool(tooltips=[(\"index\", \"@index\"), (\"error\", \"@error\")]))\n",
    "show(p)\n",
    "\n",
    "p.output_backend = \"svg\"\n",
    "_ = export_svgs(p, filename=os.path.join(IMAGE_PATH, \"thr_range_exp.svg\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d603ed9",
   "metadata": {},
   "source": [
    "![Threshold range exploration](./img/thr_range_exp.svg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a8d3dd5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "thresholds = np.arange(THRESHOLD_MIN, THRESHOLD_MAX + THRESHOLD_STEP, THRESHOLD_STEP)\n",
    "errors = []\n",
    "\n",
    "for threshold in thresholds:\n",
    "    predictions = get_prediction(stack[:, 1], threshold=threshold)\n",
    "    conf_mat = confusion_matrix(test_labels, predictions)\n",
    "    errors.append([threshold, conf_mat[1, 0], conf_mat[0, 1]])\n",
    "\n",
    "errors = np.array(errors)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "455bb9cc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "THRESHOLD = 6\n",
    "predictions = get_prediction(stack[:, 1], threshold=THRESHOLD)\n",
    "\n",
    "plot_confusion_matrix(\n",
    "    confusion_matrix(test_labels, predictions),\n",
    "    model_name=MODEL_NAME,\n",
    "    file_name=os.path.join(IMAGE_PATH, \"conf_mat.svg\"),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc412337",
   "metadata": {},
   "source": [
    "![Confusion Matrix](./img/conf_mat.svg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5f8f68e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 91.67%, Precision: 90.91%, Recall: 90.91%, F1: 90.91%\n"
     ]
    }
   ],
   "source": [
    "print(\n",
    "    f\"Accuracy: {accuracy_score(test_labels, predictions):.2%}, \\\n",
    "Precision: {precision_score(test_labels, predictions):.2%}, \\\n",
    "Recall: {recall_score(test_labels, predictions):.2%}, \\\n",
    "F1: {f1_score(test_labels, predictions):.2%}\"\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
